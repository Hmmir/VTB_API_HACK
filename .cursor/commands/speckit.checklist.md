---
description: Generate a custom checklist for the current feature - "Unit Tests for Requirements Writing"
---

## Checklist Purpose: "Unit Tests for English"

**CRITICAL CONCEPT**: Checklists are **UNIT TESTS FOR REQUIREMENTS WRITING** - they validate the quality, clarity, and completeness of requirements in a given domain.

**NOT for verification/testing**:
- ‚ùå NOT "Verify the button clicks correctly"
- ‚ùå NOT "Test error handling works"
- ‚ùå NOT checking if code/implementation matches the spec

**FOR requirements quality validation**:
- ‚úÖ "Are visual hierarchy requirements defined for all card types?" (completeness)
- ‚úÖ "Is 'prominent display' quantified with specific sizing/positioning?" (clarity)
- ‚úÖ "Are hover state requirements consistent across all interactive elements?" (consistency)

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Execution Steps

1. **Setup**: Run `.specify/scripts/powershell/check-prerequisites.ps1 -Json` from repo root and parse JSON for FEATURE_DIR and AVAILABLE_DOCS list.

2. **Clarify intent (dynamic)**: Derive up to THREE initial contextual clarifying questions. They MUST:
   - Be generated from the user's phrasing + extracted signals from spec/plan/tasks
   - Only ask about information that materially changes checklist content
   - Be skipped individually if already unambiguous in `$ARGUMENTS`

3. **Understand user request**: Combine `$ARGUMENTS` + clarifying answers:
   - Derive checklist theme (e.g., security, review, deploy, ux)
   - Consolidate explicit must-have items mentioned by user
   - Map focus selections to category scaffolding

4. **Load feature context**: Read from FEATURE_DIR:
   - spec.md: Feature requirements and scope
   - plan.md (if exists): Technical details, dependencies
   - tasks.md (if exists): Implementation tasks

5. **Generate checklist** - Create "Unit Tests for Requirements":
   - Create `FEATURE_DIR/checklists/` directory if it doesn't exist
   - Generate unique checklist filename:
     - Use short, descriptive name based on domain (e.g., `ux.md`, `api.md`, `security.md`)
     - Format: `[domain].md`
     - If file exists, append to existing file
   - Number items sequentially starting from CHK001
   - Each `/speckit.checklist` run creates a NEW file

   **CORE PRINCIPLE - Test the Requirements, Not the Implementation**:
   Every checklist item MUST evaluate the REQUIREMENTS THEMSELVES for:
   - **Completeness**: Are all necessary requirements present?
   - **Clarity**: Are requirements unambiguous and specific?
   - **Consistency**: Do requirements align with each other?
   - **Measurability**: Can requirements be objectively verified?
   - **Coverage**: Are all scenarios/edge cases addressed?

   **Category Structure** - Group items by requirement quality dimensions:
   - **Requirement Completeness**
   - **Requirement Clarity**
   - **Requirement Consistency**
   - **Acceptance Criteria Quality**
   - **Scenario Coverage**
   - **Edge Case Coverage**
   - **Non-Functional Requirements**
   - **Dependencies & Assumptions**
   - **Ambiguities & Conflicts**

   **HOW TO WRITE CHECKLIST ITEMS**:

   ‚ùå **WRONG** (Testing implementation):
   - "Verify landing page displays 3 episode cards"
   - "Test hover states work on desktop"

   ‚úÖ **CORRECT** (Testing requirements quality):
   - "Are the exact number and layout of featured episodes specified?" [Completeness]
   - "Is 'prominent display' quantified with specific sizing/positioning?" [Clarity]
   - "Are hover state requirements consistent across all interactive elements?" [Consistency]

   **ITEM STRUCTURE**:
   - Question format asking about requirement quality
   - Focus on what's WRITTEN (or not written) in the spec/plan
   - Include quality dimension in brackets
   - Reference spec section `[Spec ¬ßX.Y]` when checking existing requirements
   - Use `[Gap]` marker when checking for missing requirements

   **Traceability Requirements**:
   - MINIMUM: ‚â•80% of items MUST include at least one traceability reference
   - Each item should reference: `[Spec ¬ßX.Y]`, `[Gap]`, `[Ambiguity]`, `[Conflict]`, `[Assumption]`

   **üö´ ABSOLUTELY PROHIBITED**:
   - ‚ùå Any item starting with "Verify", "Test", "Confirm", "Check" + implementation behavior
   - ‚ùå References to code execution, user actions, system behavior
   - ‚ùå Test cases, test plans, QA procedures

   **‚úÖ REQUIRED PATTERNS**:
   - ‚úÖ "Are [requirement type] defined/specified/documented for [scenario]?"
   - ‚úÖ "Is [vague term] quantified/clarified with specific criteria?"
   - ‚úÖ "Are requirements consistent between [section A] and [section B]?"
   - ‚úÖ "Can [requirement] be objectively measured/verified?"

6. **Report**: Output full path to created checklist, item count, and summary:
   - Focus areas selected
   - Depth level
   - Any explicit user-specified must-have items incorporated

## Example Checklist Types

**UX Requirements Quality:** `ux.md`
- "Are visual hierarchy requirements defined with measurable criteria? [Clarity, Spec ¬ßFR-1]"
- "Is the number and positioning of UI elements explicitly specified? [Completeness]"
- "Are accessibility requirements specified for all interactive elements? [Coverage, Gap]"

**API Requirements Quality:** `api.md`
- "Are error response formats specified for all failure scenarios? [Completeness]"
- "Are rate limiting requirements quantified with specific thresholds? [Clarity]"

**Security Requirements Quality:** `security.md`
- "Are authentication requirements specified for all protected resources? [Coverage]"
- "Are data protection requirements defined for sensitive information? [Completeness]"

